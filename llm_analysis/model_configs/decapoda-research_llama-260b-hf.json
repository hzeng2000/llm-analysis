{
    "name": "decapoda-research_llama-260b-hf",
    "num_layers": 128,
    "n_head": 100,
    "hidden_dim": 16384,
    "vocab_size": 32000,
    "max_seq_len": 2048,
    "ffn_embed_dim": 65536,
    "model_type": "llama",
    "param_count": 260
}